---
title: 状态机
date: 2022-03-01 21:56:42
tags: kafka
---

# 一、引言
[上文把KafkaController基本功能梳理了一遍](http://blog.hellolc.com/2022/02/20/KafkaController%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/)， 让我们稍微对KafkaController的功能了解了一下， 认真看完的同学， 应该觉得不是非常复杂。
状态机部分其实也不是非常复杂，主要是比较细碎，如果只讲Kafka状态机部分， 大家也许就无法理解Kafka的设计意图和精髓。 
为了让大家更好理解状态机部分， 我会围绕一个Topic的生命周期，给大家讲解Kafka状态机从中扮演的角色，这样不仅可以让大家更好的理解状态机， 而且可以对上面讲解的KafkaController整体功能进行巩固。


# 二、 什么是状态机
首先我们先了解一下Kafka状态机是什么？
Kafka状态机是KafkaController的一部分组件， 它由**分区状态机管理器（PartitionStateMachine）**和**副本状态机管理器（ReplicaStateMachine）**组成，统一由KafkaController来管理，也就是只有成为了集群的Controller，才能操控修改状态机信息。
**Kafka状态机管理着所有Topic的分区和副本的状态信息**。也就是说当有Broker节点发生上下线时，KafkaController可以调用Kafka状态机，根据目前存活的Broker节点情况， 重新分配Topic的分区leader信息和副本状态。
拿之前例子， testA Topic的0号分区，分布在各个Broker节点上，101节点上的副本是这个分区的leader，但当**101发生宕机**时，假设102节点竞选到集群的Controller，然后Controller必须要对分区leader做出调整， 否则此分区服务就不可用了。因此KafkaController会调用分区状态机， 将**0号分区的leader分配给102的副本**，这样这个分区就又能恢复服务了。

Kafka的分区leader才对外进行服务， 其他副本在成为分区leader前，不对外服务， 只向分区leader同步复制数据。

那这里大家肯定会有几个疑问？
1.为何选择102的副本作为leader？
2.如何保证切换到102后， 整体数据是一致的，不存在丢失情况？
这些问题接下来会陆续给大家解答的。
![image.png](https://img.alicdn.com/imgextra/i4/O1CN01dEruAA1DtXIYAClJ2_!!6000000000274-2-tps-2932-2176.png)

## 2.1 从Topic创建开始
我们还是以上面的例子为例，创建一个名叫testA的topic， 它有1个分区， 同时一个分区有3个副本。
当我们通过工具进行创建topic时， 最终会调用到下面这块代码。
![image.png](https://img.alicdn.com/imgextra/i1/O1CN01Gmxrqz1kkGbQhoalH_!!6000000004721-2-tps-1906-442.png)

1. 首先会将这个topic相关的配置信息(json格式)，比如是否compact，unclean等功能， 写入到/config/topics/testA这个zk节点下面，后续节点failover的时候会用到这个配置， 先记住哈。
1. 创建topic的默认AR信息， 也就是topic分区副本的默认分配情况，写入到/brokers/topics/testA下, 它的内容大致为如下， 也就是说0号分区的副本，分布在101，103，102，同时默认情况下101为分区的leader。
```scala
{"version":1,"partitions":{"0":[101,103,102]}}
```

## 2.2 Topic相关初始化
那KafkaController是如何知道有新topic创建呢？
还记得在我们上面讲KafkaControllerFailover时， 会进行注册一堆zookeeper监听事件吗？
其中topicChangeHandler就是监听/brokers/topics/节点下子节点变化的。
![image.png](https://img.alicdn.com/imgextra/i1/O1CN01yYBY3P1wZz6N1hJgH_!!6000000006323-2-tps-2202-308.png)
![image.png](https://img.alicdn.com/imgextra/i1/O1CN019ss0kK1ufMWEKUwYW_!!6000000006064-2-tps-2452-836.png)
当/brokers/topics的子节点变化时， 就会调用topicChange方法， 其主要操作如下：

1. 先从zookeeper上获取/brokers/topics/节点下所有的topic信息；
1. 根据之前的全量topic信息， 找出新增的topic， 也就是刚创建的testA；
1. 然后将最新的全部topic信息更新到controllerContext.allTopics上；
1. 然后注册监听testA的分区变化情况， 也就是说一旦后续testA发生扩展分区，就会触发相应的逻辑， 这块我们后面再说；
1. 更新testA的AR信息，也就是把这个topic的分区所对应的副本分布在哪个节点上的信息，记录到controllerContext.partitionAssignments对象上，这个信息之前强调过， 非常重要， 大家记住哈；
1. 上面这些操作都是逻辑概念的操作，最后需要调用状态机进行分区和副本操作， 才能产生实际效果的操作；


## 2.3 状态机变动
那状态机是如何将testA的0号分区的副本， 分别部署在101，103，102上的呢？我们看下对应的代码。
![image.png](https://img.alicdn.com/imgextra/i4/O1CN01abL29s1mTRHO9y6Pm_!!6000000004955-2-tps-1942-490.png)
### 第一步：分区初始化
首先分区状态机， 会将testA的0号分区的状态设置为NewPartition；这一步其实没做什么实质事情， 只是将controllerContext对象对应的分区状态信息修改了一下， 为后续状态变更做准备；![image.png](https://img.alicdn.com/imgextra/i1/O1CN01fbbuNh1uADaUNN0e5_!!6000000005996-2-tps-1162-342.png)
### 第二步：副本初始化
第二步是调用副本状态机，从AR对象(前文提到的controllerContext.partitionAssignments)中， 获取这个0号分区对应的所有副本对象，然后进行修改其状态信息， 由于目前controllerContext.partitionLeadershipInfo队里里是没有对应分区的leaderAndIsr信息的， 因此这里也只是修改了一下副本的状态为 NewPartition，为后续的状态变更做准备；![image.png](https://img.alicdn.com/imgextra/i4/O1CN01B3e1Ab1NJUHV4uhiP_!!6000000001549-2-tps-1592-666.png)
### 第三步：初始化LeaderAndIsr
从第三步开始，就和之前的操作有所变化了，这步也是这四步里最重要的一步。![image.png](https://img.alicdn.com/imgextra/i4/O1CN01CHKhrp1fbxL04dDl3_!!6000000004026-2-tps-2622-386.png)
由于我们第一步将分区的状态变为NewPartition了，因此会走初始化leaderAndIsr的逻辑。
![image.png](https://img.alicdn.com/imgextra/i1/O1CN01c6BNIw28MxDpM6TV0_!!6000000007919-2-tps-2344-1284.png)
初始化leaderAndIsr逻辑大致如下：

1. 根据分区，从AR对象中获取副本信息， 也就是testA的0号分区的所有副本信息；
1. 根据存活的broker节点， 过滤掉在宕机节点上的副本，由于我们没有宕机的节点，因此不会过滤掉任何副本；
1. 封装leaderAndIsr对象, 将AR队列中的第一个副本作为分区的leader，所有副本作为默认的isr（insyncReplicas）对象，什么是isr对象呢？ 你可以暂时理解为与leader副本数据同步的副本，具体细节，我们稍微再讲，leaderAndIsr对象的内容大致如下：
```scala
{"controller_epoch":86,"leader":101,"version":1,"leader_epoch":2,"isr":[103,102,101]}
```

4. 将leaderAndIsr信息存储在/brokers/topics/testA/partitions/0/state节点上；这里有个细节， 需要大家注意，我们创建节点时， 会传递controllerContext.epochZkVersion参数， 它具体是做什么用的呢？大家先思考一下， 我们后面再来揭晓原因。
4. 将创建成功的leaderAndIsr的分区， 存在在partitionLeadershipInfo对象上，这个对象之前讲过非常重要，后续就经常用到；
4. 记录下信息， 后续将leaderAndIsr发送给各个节点，将对应的副本做相应事情， leader副本开始对外进行服务， 其他副本从leader上复制数据，这块我们后面再细讲；

总结一下第三步的操作， 就是确定谁是这个分区的leader，谁是这个分区的isr，然后封装leaderAndIsr持久化到zookeeper节点上， 最后发送给各个broker节点上的副本， 让他们做相应的操作（具体操作详情， 我们稍稍后再讲）。

### 第四步： 修改副本状态
第四步逻辑也比较简单：

1. 首先判断副本所在的broker节点是否都在AR集合里， 如果不存在则将broker节点添加到对应的AR集合里，我们目前这个例子是不会触发这个逻辑的；
1. 然后将副本状态从NewReplica，改变为OnlineReplica；

![image.png](https://img.alicdn.com/imgextra/i4/O1CN01TebDFg1lCf9tUU0ff_!!6000000004783-2-tps-1672-1208.png)

## 2.4 状态机信息同步方式
刚上面简单了解了一部分的状态机变化，大家现在比较肯定比较迷惑，KafkaController虽然让状态机发生了变化， 但对应的broker节点上的副本是怎么知道自己的状态的呢？
这就需要讲下KafkaController与各broker节点之间的信息同步方式， KafkaController会向其他节点发送LeaderAndIsrRequest和UpdateMetadataRequest请求来同步状态机信息。

### 封装 LeaderAndIsrRequest
以上面状态机变化的第三步为例，当我们将封装好的leaderAndIsr好后， 会调用addLeaderAndIsrRequestForBrokers方法，封装状态机信息为leaderAndIsrRequest，然后将请求， 发送给对应broker节点。
我们来看看它的具体逻辑
![image.png](https://img.alicdn.com/imgextra/i1/O1CN01QwjzBC1V6DjgHLG1c_!!6000000002603-2-tps-1984-172.png)
![image.png](https://img.alicdn.com/imgextra/i2/O1CN01DbBqE71KZZLEYLJIj_!!6000000001178-2-tps-1818-1136.png)
![image.png](https://img.alicdn.com/imgextra/i2/O1CN01f4Sux21hb9sfFb7nw_!!6000000004295-2-tps-1846-920.png)

1. addLeaderAndIsrRequestForBrokers的主要逻辑是聚合一个全局的leaderAndIsrRequestMap对象，它的key是brokerId， 也就是请求要发往的brokerId，它的内容就是又LeaderAndIsr内容封装的LeaderAndIsrPartitionState；
1. 聚合完毕这次相关的分区信息后， 就会通过controllerChannelManager 发送RPC请求给相应的broker节点， 逻辑也比较简单， 这里就不细讲了，敢兴趣的同学可自信查看。
1. 接下来又会调用addUpdateMetadataRequestForBrokers来封装UpdateMetadata请求；
### 封装 UpdateMetadataRequest
![image.png](https://img.alicdn.com/imgextra/i4/O1CN01amNvrw20G4LHiIxyx_!!6000000006821-2-tps-1664-1332.png)
![image.png](https://img.alicdn.com/imgextra/i4/O1CN010Nmtzb1kr8Xi2dGT2_!!6000000004736-2-tps-1770-1018.png)

1. addUpdateMetadataRequestForBrokers的逻辑和上面封装leaderAndIsr请求差不多， 首先将要发往的brokerI加入updateMetadataRequestBrokerSet集合里；
1. 再将leaderAndIsr信息封装到updateMetadataRequestPartitionInfoMap对象里；
1. 然后发送updateMetadataRequest请求给各个节点

### 总结
我们会发现封装的leaderAndIsrRequest和updateMetadataRequest对象数据结构是类似的， 无非leaderAndIsr请求会多几个参数， 用于副本创建和迁移，我们后面再细讲。

虽然他们数据结构类似，但是他们发送的broker节点是不同的：

1. leaderAndIsrRequest是发往所有AR副本上，由于是初始化操作， 因此AR副本等于isr节点；
1. 但是updateMetadataRequest是发往所有存活的broker节点上；

因此updateMetadataRequest发往的节点数是大于等于leaderAndIsrRequest发往的节点数的。
为什么会这样呢？
你可以这样理解：

1. LeaderAndIsrRequest是控制分区副本做相应操作的， 只有broker节点上有对应的分区副本才会收到请求；
1. UpdateMetadataRequest是将当前集群的分区副本分配情况同步给所有节点， 这样你请求任何一个broker节点时， 都能获取最新的分区副本分配的metadata信息；
1. 一旦有LeaderAndIsrRequest必然会有UpdateMetadataRequest请求

 
## 2.5 处理 UpdateMetadataRequest
上面简单介绍了LeaderAndIsrRequest和UpdateMetadataRequest这2个请求的封装过程。
我们先来看下UpdateMetadataRequest请求的具体处理逻辑。

它会调用ReplicaManager.maybeUpdateMetadataCache方法。
ReplicaManager顾名思义， 它管理这broker上所有的副本信息；它内部还维护了一个metadataCache对象；
最终会调用metadataCache.updateMetadata方法， 它的逻辑也非常简单。
![image.png](https://img.alicdn.com/imgextra/i1/O1CN01A2a5C71XFxO1CvgaF_!!6000000002895-2-tps-2326-460.png)
核心就是上面这段代码， 它会将发送来的metadata信息，也就是LeaderAndIsr信息存储在metadataSnapshot对象上。
是的， 不进行任何持久化落盘操作， 也就是说， 一旦节点宕机重启， metadata信息就会丢失， 只能等待KafkaController发送最新的metadata给它， 否则这个节点是不可用的状态。


## 2.6 处理 LeaderAndIsrRequest
那么当broker节点收到LeaderAndIsrRequest的请求的时候， 该做什么处理呢？我们来看下它们的具体处理逻辑。

broker节点收到LeaderAndIsrRequest请求后， 会调用RelicaManager.becomeLeaderOrFollower方法， 具体会做如下逻辑
![image.png](https://img.alicdn.com/imgextra/i2/O1CN01WYKTUG1XgykvkBGRH_!!6000000002954-2-tps-2044-1334.png)

1. 根据发送来的LeaderAndIsr请求封装partitionStates对象， 同时如果是新分区， 会进行初始化，具体逻辑比较简单， 我们直接忽略
1. 通过判断LeaderAndIsr请求的leader是否就是当前broker节点的Id，找出需要成为leader的副本；
1. 通过判断LeaderAndIsr请求的leader是否就是当前broker节点的Id，找出需要成为follow的副本；
1. 将前面找出来需要成为leader的副本， 做相应处理， 具体逻辑我们下面细说；
1. 将前面找出来需要成为follow的副本， 做相应处理， 具体逻辑我们下面细说；

### 成为副本Leader副本

![image.png](https://img.alicdn.com/imgextra/i2/O1CN01IgnAjH1IuWE9U8m4x_!!6000000000953-2-tps-1696-90.png)
在讲副本成为leader前， 我们可以看到会通过replicaFetcherManager将之前的fetch线程关闭掉，这是为什么呢？
在我们这次逻辑是操作中， 是没有实际意义的， 但如果对于老的副本就有意义了， 如果这个副本之前是个follower副本， 那么它之前肯定会有一个单独线程定期从leader副本同步数据。但目前自己要成为leader了， 就没必要再进行同步数据了。

成为leader副本的具体操作如下：
![image.png](https://img.alicdn.com/imgextra/i4/O1CN01664xI227OxKpupvVK_!!6000000007788-2-tps-1598-1340.png)
![image.png](https://img.alicdn.com/imgextra/i4/O1CN01vdDvHW1QJtTmwN1Oo_!!6000000001956-2-tps-1878-622.png)

1. 记录controllerEpoch, 在后续isr更新中，这个信息需要被用到；
1. 更新分区副本的isr和所有副本AR信息；
1. 如果是初始化， 在本地创建对应的数据文件， 用于存储消息数据；
1. 记录leaderEpoch, offset, zkVersion, 这些会用于后续isr更新和HW更新，非常重要， 后面细讲；
1.  将leaderEpoch与日志offset关联起来， 便于follow异常情况下truncate日志；
1. 重置follower上次来拉取数据的时间；
1. 如果是新分区的leader，初始化follower副本的上次拉取状态，这些信息也主要为后续isr更新使用；
1. 判断是否需要增加HW位点；
1. 如果HW增加， 判断是否完成同步发送的异步任务；

HW（High WaterMarker）：用户能拉取到的最大位点；


上面这块逻辑，大家先了解一下， 后面会讲下isr更新机制， 大家才能够理解。

### 成为Follower副本
成为follower副本的逻辑与成为leader副本逻辑类似，具体逻辑如下：
![image.png](https://img.alicdn.com/imgextra/i2/O1CN01mZ3oTL1Isgdoksxgm_!!6000000000949-2-tps-1622-902.png)
![image.png](https://img.alicdn.com/imgextra/i1/O1CN01ftW6R21CVQq90VkBe_!!6000000000086-2-tps-1928-640.png)

1. 记录controllerEpoch；
1. 更新分区副本的isr和所有副本AR信息；
1. 如果是初始化， 在本地创建对应的数据文件， 用于存储消息数据；
1. 记录leaderEpoch, offset, zkVersion, 这些会用于后续isr更新和HW更新，非常重要， 后面细讲；
1. 如果之前存在同步数据的线程， 先将其停止；
1. 如果之前是leader副本，尝试完成发送和消费的异步任务；
1. 启动同步数据线程， 向leader副本进行拉取数据；

### 总结
LeaderAndIsrRequest请求的主要工作就是：

1. 副本的Leader开始对外进行服务，并且维护ISR集合和HW的增加；
1. 副本的follower，另起线程对leader副本的数据进行同步，防止leader异常宕机时，可以接替成为leader；
